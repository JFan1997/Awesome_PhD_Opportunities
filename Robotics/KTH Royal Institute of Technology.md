We are looking for a motivated PhD student to join the Division of Speech, Music, and Hearing (TMH) at KTH Royal Institute of Technology in Stockholm.

This project aims to advance Human-Robot Interaction (HRI) by enhancing embodied AI, integrating multimodal social cues and task-related actions into foundation models to enable robots to communicate in a more natural and human-like manner. It addresses the current limitations of Large Language Models, which lack the ability to comprehend and generate essential social cues like facial expressions, gestures, and gaze, as well as perform task-specific behaviors. The project focuses on three key objectives: integrating multimodal perception into AI models, training these models to produce both verbal and non-verbal outputs, and developing new metrics to evaluate their performance in HRI scenarios.

The Swedish AI-program WASP funds this project. WASP's graduate school fosters a strong multidisciplinary, international network among PhD students, researchers, and industry through research visits, partner universities, and visiting lecturers.

The candidate must have a degree in Computer Science or related fields. Documented written and spoken English and programming skills are required. Some experience with artificial intelligence, robotics, human-robot interaction, and multimodal machine learning is preferred.

The student will start before mid-January of 2024, and the last application date is August 31st. Application details can be consulted through KTH’s dedicated recruitment system: [https://www.kth.se/lediga-jobb/739179?l=en](https://www.kth.se/lediga-jobb/739179?l=en)

Best regards,  
**André Pereira**  
Researcher @ KTH Royal Institute of Technology  
School of Electrical Engineering and Computer Science  
Division of Speech, Music and Hearing (TMH)
